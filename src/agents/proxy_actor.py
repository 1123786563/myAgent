from logger import get_logger
from privacy_guard import PrivacyGuard
from config_manager import ConfigManager
import json

log = get_logger("ProxyActor")

class SecurityException(Exception):
    pass

class ProxyActor:
    """
    [Optimization Round 3] ç½‘ç»œå‡ºå£å¼ºåˆ¶ä»£ç† (Egress Proxy)
    æ‰€æœ‰å¤–éƒ¨ API è¯·æ±‚å¿…é¡»ç»è¿‡æ­¤ Actorï¼Œå¼ºåˆ¶æ‰§è¡Œéšç§æ£€æŸ¥ã€‚
    å®ç°â€œæœ¬åœ°é”â€ç­–ç•¥ï¼šæ•æ„Ÿæ•°æ®åœ¨ç¦»å¼€å†…å­˜å‰å¿…é¡»è¢« PrivacyGuard è¿‡æ»¤ã€‚
    """
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ProxyActor, cls).__new__(cls)
            cls._instance.guard = PrivacyGuard(role="ProxyAdmin")
            cls._instance.strict_mode = ConfigManager.get("security.strict_mode", True)
        return cls._instance

    def _inspect_and_sanitize(self, text_content):
        """
        æ£€æŸ¥æ–‡æœ¬è´Ÿè½½ï¼Œå¼ºåˆ¶è„±æ•
        è¿”å›: (safe_text, was_modified)
        """
        if not text_content or not isinstance(text_content, str):
            return text_content, False
        
        # è°ƒç”¨ PrivacyGuard çš„ LLM ä¸“ç”¨æ¸…æ´—æ¥å£
        cleaned_text, found_sensitive = self.guard.sanitize_for_llm(text_content)
        
        if found_sensitive:
            log.warning(f"ğŸ›¡ï¸ [Proxy] æ‹¦æˆªåˆ°æ•æ„Ÿæ•°æ®ï¼å·²å¼ºåˆ¶è„±æ•ã€‚åŸæ–‡é•¿åº¦: {len(text_content)}")
            # åœ¨æåº¦ä¸¥æ ¼æ¨¡å¼ä¸‹ï¼Œå¯ä»¥é…ç½®ä¸ºç›´æ¥ç†”æ–­æŠ›é”™
            # if self.strict_mode:
            #     raise SecurityException("Data Leak Prevention: Blocked outbound request containing PII.")
            return cleaned_text, True
            
        return cleaned_text, False

    def send_llm_request(self, client, model, messages, **kwargs):
        """
        ä»£ç† LLM è¯·æ±‚ (OpenAI SDK Compatible)
        æ‹¦æˆª messages ä¸­çš„ contentï¼Œè¿›è¡Œå¼ºåˆ¶è„±æ•åå†å‘ç»™ client
        """
        log.info(f"ğŸ”’ ProxyIntercept: Outbound LLM Request -> {model}")
        
        safe_messages = []
        modified_count = 0
        
        for msg in messages:
            content = msg.get("content", "")
            if isinstance(content, str):
                safe_content, modified = self._inspect_and_sanitize(content)
                if modified: modified_count += 1
                safe_messages.append({
                    "role": msg["role"], 
                    "content": safe_content
                })
            else:
                # å¤„ç†å¤æ‚ content (å¦‚ multimodal list)
                # ç®€åŒ–å¤„ç†ï¼šæš‚æ—¶åŸæ ·æ”¾è¡Œéæ–‡æœ¬ï¼Œå®é™…åº”é€’å½’æ£€æŸ¥
                safe_messages.append(msg)
        
        if modified_count > 0:
            log.info(f"ğŸ”’ Proxy å®‰å…¨æŠ¥å‘Š: ä¿®æ”¹äº† {modified_count} æ¡æ¶ˆæ¯ä¸­çš„æ•æ„Ÿå†…å®¹ã€‚")

        # Forward call to the actual client
        # è¿™ä¸€æ­¥æ˜¯å®é™…çš„ç½‘ç»œ IO
        try:
            return client.chat.completions.create(
                model=model,
                messages=safe_messages,
                **kwargs
            )
        except Exception as e:
            log.error(f"ğŸ”’ Proxy è½¬å‘å¤±è´¥: {e}")
            raise e

    def validate_url_request(self, url):
        """
        ä»£ç† HTTP URL æ£€æŸ¥ (ç”¨äº Browser Connector)
        """
        log.info(f"ğŸ”’ ProxyIntercept: Checking URL -> {url}")
        
        # ç®€å•çš„ç™½åå•/é»‘åå•é€»è¾‘
        allowed_hosts = ["mock-bank-portal.internal", "api.openai.com", "127.0.0.1"]
        if not any(host in url for host in allowed_hosts):
            log.warning(f"âš ï¸ è®¿é—®äº†éç™½åå•åŸŸå: {url}")
            # if self.strict_mode: raise SecurityException(f"URL blocked by policy: {url}")
        
        return True
